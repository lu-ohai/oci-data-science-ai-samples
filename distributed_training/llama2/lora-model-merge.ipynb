{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81652054",
   "metadata": {},
   "source": [
    "# Merge the fine-tuned model\n",
    "\n",
    "To try your fine-tuned Llama2 model, you have to merge it with the foundational base model version used for the fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794123c9",
   "metadata": {},
   "source": [
    "`Make sure to install the required dependancies first, preferable in Conda environment with PyTorch 2.0+`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e443ed9",
   "metadata": {},
   "source": [
    "Before you start make sure that you've installed the `pytorch20_p39_gpu_v2` Conda and activate it in the `Terminal`\n",
    "\n",
    "```bash\n",
    "odsc conda install -s pytorch20_p39_gpu_v2\n",
    "```\n",
    "\n",
    "... then activate it\n",
    "\n",
    "```bash\n",
    "conda activate /home/datascience/conda/pytorch20_p39_gpu_v2\n",
    "```\n",
    "\n",
    "Then continue by starting the notebook and selecting the `pytorch20_p39_gpu_v2` as Python Kernel, then install the dependancies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tokenizers==0.13.3 -U && pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import PeftModel\n",
    "from peft.utils import PeftConfig\n",
    "import torch\n",
    "    \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65973d",
   "metadata": {},
   "source": [
    "Set the variables to point to:\n",
    "\n",
    "`ft_model` - the location of the object storage mount to your OCI Data Science Notebook where the PEFT weights where stored\n",
    "`output_dir` - where to store the merged weights, preferably again on object storage\n",
    "`base_model_name_or_path` - name of the model card as available in Hugging Face\n",
    "`your_huggingface_auth_token` - your Hugging Face auth token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa64762",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = \"/mnt/llama2/outputs/13b-hf/ocid1.datasciencejob.oc1.eu-frankfurt-1.amaaaaaan\"\n",
    "\n",
    "output_dir = \"/mnt/llama2/llama2-ft-lora-13b-merged\"\n",
    "\n",
    "base_model_name_or_path = \"meta-llama/Llama-2-13b-hf\"\n",
    "\n",
    "your_huggingface_auth_token = \"<your-huggingface-login-token>\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path, use_auth_token=your_huggingface_auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name_or_path,\n",
    "    device_map=\"auto\", \n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_auth_token=your_huggingface_auth_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2903e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(base_model, ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nModel architecture before merging\", flush=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()\n",
    "\n",
    "print(f\"\\nModel architecture after merging\", flush=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12970c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=True,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = \"\"\"Martin: I won two cinema tickets! Aggie: oh cool, how come? Martin: online. on fb, the movie mag organized it Aggie: so what did you do Martin: just write a short review and that's it Aggie: well done :) so what and when. and where? Martin: the new film with Redford Aggie: i guess i heard sth Martin: it's pretty cool i heard. till the end of the week Aggie: sounds good. we'll find time XD\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6595dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ppl(f\"Summarize this dialog:\\n{dialog}\\n---\",\n",
    "    max_length=200,\n",
    "        temperature=0.95,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5882466",
   "metadata": {},
   "source": [
    "# Export to Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66181dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from ads.model.datascience_model import DataScienceModel\n",
    "from ads.common.auth import default_signer\n",
    "import ads\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39477859",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.set_auth(\"resource_principal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d575b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH=output_dir\n",
    "ARTFICAT_FILE_NAME=f\"{os.path.basename(output_dir)}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5976999",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(ARTFICAT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbca414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_archive_file = shutil.make_archive(ARTFICAT_FILE_NAME, format=\"zip\", root_dir=MODEL_PATH)\n",
    "!zip -0 -rj $ARTFICAT_FILE_NAME $MODEL_PATH/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(ARTFICAT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DISPLAY_NAME = \"LLama2-FT-Lora-13b-Samsum\"\n",
    "bucket = \"your bucket\"\n",
    "namespace = \"your namespace\"\n",
    "OCI_BUCKET = f\"oci://{bucket}@{namespace}/datascience-large-artifact-store/\" # For large models we first upload the model to object storag and then provide the object storage location while creating model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ef13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DataScienceModel()\n",
    "model = (\n",
    "    model.with_display_name(MODEL_DISPLAY_NAME)\n",
    "    .with_artifact(ARTFICAT_FILE_NAME)\n",
    ")\n",
    "model.create(bucket_uri=OCI_BUCKET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffedc02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch20_p39_gpu_v2]",
   "language": "python",
   "name": "conda-env-pytorch20_p39_gpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
